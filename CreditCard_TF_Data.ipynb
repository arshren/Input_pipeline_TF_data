{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "from tensorflow.keras import optimizers, callbacks\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import os\n",
    "from os import getcwd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import multiprocessing\n",
    "import time\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## https://www.kaggle.com/mlg-ulb/creditcardfraud?select=creditcard.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By default, a TextLineDataset yields every line of each file, including a header line. Header can be removed using the Dataset.skip() or Dataset.filter() transformations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'C:\\data\\Data_Class\\creditcard.csv', index_col=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      "Time      284807 non-null float64\n",
      "V1        284807 non-null float64\n",
      "V2        284807 non-null float64\n",
      "V3        284807 non-null float64\n",
      "V4        284807 non-null float64\n",
      "V5        284807 non-null float64\n",
      "V6        284807 non-null float64\n",
      "V7        284807 non-null float64\n",
      "V8        284807 non-null float64\n",
      "V9        284807 non-null float64\n",
      "V10       284807 non-null float64\n",
      "V11       284807 non-null float64\n",
      "V12       284807 non-null float64\n",
      "V13       284807 non-null float64\n",
      "V14       284807 non-null float64\n",
      "V15       284807 non-null float64\n",
      "V16       284807 non-null float64\n",
      "V17       284807 non-null float64\n",
      "V18       284807 non-null float64\n",
      "V19       284807 non-null float64\n",
      "V20       284807 non-null float64\n",
      "V21       284807 non-null float64\n",
      "V22       284807 non-null float64\n",
      "V23       284807 non-null float64\n",
      "V24       284807 non-null float64\n",
      "V25       284807 non-null float64\n",
      "V26       284807 non-null float64\n",
      "V27       284807 non-null float64\n",
      "V28       284807 non-null float64\n",
      "Amount    284807 non-null float64\n",
      "Class     284807 non-null int64\n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182276 train examples\n",
      "45569 validation examples\n",
      "56962 test examples\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(df, test_size=0.2)\n",
    "train, val = train_test_split(train, test_size=0.2)\n",
    "print(len(train), 'train examples')\n",
    "print(len(val), 'validation examples')\n",
    "print(len(test), 'test examples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an input pipeline using tf.data\n",
    "__Next, wrap the dataframes with tf.data.__\n",
    "\n",
    "__This will enable us to use feature columns as a bridge to map from the columns in the Pandas dataframe to features used to train the model.__ \n",
    "__If we were working with a very large CSV file (so large that it does not fit into memory), we would use tf.data to read it from disk directly. That is not covered in this tutorial.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A utility method to create a tf.data dataset from a Pandas Dataframe\n",
    "def df_to_dataset(dataframe, label,shuffle=True, batch_size=32, ):\n",
    "  df = dataframe.copy()\n",
    "  labels = df.pop(label)\n",
    "  ds = tf.data.Dataset.from_tensor_slices((dict(df), labels))\n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(buffer_size=len(df))\n",
    "  ds = ds.batch(batch_size)\n",
    "  return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4 # A small batch sized is used for demonstration purposes\n",
    "train_ds = df_to_dataset(train,'Class', batch_size=batch_size)\n",
    "val_ds = df_to_dataset(val,'Class', shuffle=False, batch_size=batch_size)\n",
    "test_ds = df_to_dataset(test,'Class', shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After creating the the input pipeline, check to see the format of the data it returns with  a small batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every feature: ['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount']\n",
      "A batch of Amount: tf.Tensor([ 0.76 10.   29.95 18.88], shape=(4,), dtype=float64)\n",
      "A batch of Class: tf.Tensor([0 0 0 0], shape=(4,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for feature_batch, label_batch in train_ds.take(1):\n",
    "  print('Every feature:', list(feature_batch.keys()))\n",
    "  print('A batch of Amount:', feature_batch['Amount'])\n",
    "  print('A batch of Class:', label_batch )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
       "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
       "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount',\n",
       "       'Class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = []\n",
    "\n",
    "# numeric cols\n",
    "for header in ['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
    "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
    "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount']:\n",
    "  feature_columns.append(feature_column.numeric_column(header))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NumericColumn(key='V1', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='V2', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='V3', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='V4', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='V5', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='V6', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='V7', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='V8', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='V9', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='V10', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='V11', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='V12', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='V13', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='V14', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='V15', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='V16', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='V17', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='V18', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='V19', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='V20', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='V21', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='V22', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='V23', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='V24', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='V25', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='V26', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='V27', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='V28', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='Amount', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a feature layer, we have defined our feature columns, we will use a DenseFeatures layer to input them to our Keras model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_layer = tf.keras.layers.DenseFeatures(feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_ds = df_to_dataset(train,'Class', batch_size=batch_size)\n",
    "val_ds = df_to_dataset(val, 'Class', shuffle=False, batch_size=batch_size)\n",
    "test_ds = df_to_dataset(test, 'Class',shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'Time': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float64>, 'V1': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float64>, 'V2': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=float64>, 'V3': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float64>, 'V4': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float64>, 'V5': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float64>, 'V6': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float64>, 'V7': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=float64>, 'V8': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float64>, 'V9': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float64>, 'V10': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float64>, 'V11': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float64>, 'V12': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float64>, 'V13': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float64>, 'V14': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float64>, 'V15': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float64>, 'V16': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=float64>, 'V17': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=float64>, 'V18': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float64>, 'V19': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float64>, 'V20': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float64>, 'V21': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float64>, 'V22': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float64>, 'V23': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float64>, 'V24': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float64>, 'V25': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float64>, 'V26': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float64>, 'V27': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float64>, 'V28': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float64>, 'Amount': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float64>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layer dense_features is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'Time': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float64>, 'V1': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float64>, 'V2': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=float64>, 'V3': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float64>, 'V4': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float64>, 'V5': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float64>, 'V6': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float64>, 'V7': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=float64>, 'V8': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float64>, 'V9': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float64>, 'V10': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float64>, 'V11': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float64>, 'V12': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float64>, 'V13': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float64>, 'V14': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float64>, 'V15': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float64>, 'V16': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=float64>, 'V17': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=float64>, 'V18': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float64>, 'V19': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float64>, 'V20': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float64>, 'V21': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float64>, 'V22': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float64>, 'V23': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float64>, 'V24': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float64>, 'V25': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float64>, 'V26': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float64>, 'V27': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float64>, 'V28': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float64>, 'Amount': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float64>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "5697/5697 [==============================] - ETA: 0s - loss: 0.0287 - accuracy: 0.9989WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'Time': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float64>, 'V1': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float64>, 'V2': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=float64>, 'V3': <tf.Tensor 'ExpandDims_23:0' shape=(None, 1) dtype=float64>, 'V4': <tf.Tensor 'ExpandDims_24:0' shape=(None, 1) dtype=float64>, 'V5': <tf.Tensor 'ExpandDims_25:0' shape=(None, 1) dtype=float64>, 'V6': <tf.Tensor 'ExpandDims_26:0' shape=(None, 1) dtype=float64>, 'V7': <tf.Tensor 'ExpandDims_27:0' shape=(None, 1) dtype=float64>, 'V8': <tf.Tensor 'ExpandDims_28:0' shape=(None, 1) dtype=float64>, 'V9': <tf.Tensor 'ExpandDims_29:0' shape=(None, 1) dtype=float64>, 'V10': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float64>, 'V11': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float64>, 'V12': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float64>, 'V13': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float64>, 'V14': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float64>, 'V15': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float64>, 'V16': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=float64>, 'V17': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=float64>, 'V18': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float64>, 'V19': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float64>, 'V20': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float64>, 'V21': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float64>, 'V22': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float64>, 'V23': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float64>, 'V24': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float64>, 'V25': <tf.Tensor 'ExpandDims_19:0' shape=(None, 1) dtype=float64>, 'V26': <tf.Tensor 'ExpandDims_20:0' shape=(None, 1) dtype=float64>, 'V27': <tf.Tensor 'ExpandDims_21:0' shape=(None, 1) dtype=float64>, 'V28': <tf.Tensor 'ExpandDims_22:0' shape=(None, 1) dtype=float64>, 'Amount': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float64>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "5697/5697 [==============================] - 26s 5ms/step - loss: 0.0287 - accuracy: 0.9989 - val_loss: 0.0195 - val_accuracy: 0.9988\n",
      "Epoch 2/10\n",
      "5697/5697 [==============================] - 26s 5ms/step - loss: 0.0077 - accuracy: 0.9993 - val_loss: 0.0144 - val_accuracy: 0.9989\n",
      "Epoch 3/10\n",
      "5697/5697 [==============================] - 27s 5ms/step - loss: 0.0091 - accuracy: 0.9991 - val_loss: 0.0234 - val_accuracy: 0.9990\n",
      "Epoch 4/10\n",
      "5697/5697 [==============================] - 27s 5ms/step - loss: 0.0072 - accuracy: 0.9992 - val_loss: 0.0056 - val_accuracy: 0.9992\n",
      "Epoch 5/10\n",
      "5697/5697 [==============================] - 25s 4ms/step - loss: 0.0073 - accuracy: 0.9992 - val_loss: 0.0071 - val_accuracy: 0.9993\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5697/5697 [==============================] - 25s 4ms/step - loss: 0.0054 - accuracy: 0.9994 - val_loss: 0.0103 - val_accuracy: 0.9993\n",
      "Epoch 7/10\n",
      "5697/5697 [==============================] - 25s 4ms/step - loss: 0.0054 - accuracy: 0.9993 - val_loss: 0.0072 - val_accuracy: 0.9993\n",
      "Epoch 8/10\n",
      "5697/5697 [==============================] - 25s 4ms/step - loss: 0.0052 - accuracy: 0.9994 - val_loss: 0.0055 - val_accuracy: 0.9994\n",
      "Epoch 9/10\n",
      "5697/5697 [==============================] - 25s 4ms/step - loss: 0.0060 - accuracy: 0.9994 - val_loss: 0.0063 - val_accuracy: 0.9993\n",
      "Epoch 10/10\n",
      "5697/5697 [==============================] - 25s 4ms/step - loss: 0.0054 - accuracy: 0.9994 - val_loss: 0.0055 - val_accuracy: 0.9993\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x196ec7f01c8>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  feature_layer,\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dropout(.1),\n",
    "  layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_ds,\n",
    "          validation_data=val_ds,\n",
    "          epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/structured_data/feature_columns.ipynb#scrollTo=_YJPPb3xTPeZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
